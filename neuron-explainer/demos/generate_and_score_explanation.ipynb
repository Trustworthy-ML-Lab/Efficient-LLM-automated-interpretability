{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainer: HighlightSummary - Cutoff:1.008\n",
      "\n",
      "Printing explanation prompt\n",
      "-\n",
      "system: We're studying neurons in a neural network, trying to identify their roles. Look at the parts/tokens of the document the neuron activates highly for and summarize in a single sentence what the neuron is looking for. Don't list examples of words.\n",
      "\n",
      "We will show short text excerpts, where each highly activating token(part of word) is highlighted using square brackets, i.e. [token]. This is followed by a comma separated list of only the highly activating tokens. Your task is to summarize what the highly activating tokens have in common, taking their context into account.\n",
      "\n",
      "user: \n",
      "\n",
      "Neuron 1\n",
      "Activations:\n",
      "\n",
      " Text excerpt - A:\n",
      "<start>turturro is fabulously funny and over the top as a 'very sneaky' butler who excels in the art of impossible[ disappearing]/reapp[earing] acts<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " disappearing,earing\n",
      "\n",
      " Text excerpt - B:\n",
      "<start>esc[aping][ the] studio , piccoli is warmly[ affecting] and so is this adroitly minimalist movie .<end> \n",
      "\n",
      "Highly activating tokens:\n",
      "aping, the, affecting\n",
      "\n",
      "Explanation of neuron 1 behavior: the main thing this neuron does is find\n",
      "\n",
      "assistant:  present tense verbs ending in 'ing'.\n",
      "\n",
      "user: \n",
      "\n",
      "Neuron 2\n",
      "Activations:\n",
      "\n",
      " Text excerpt - A:\n",
      "<start>as saccharine movies go , this is likely to cause massive cardiac[ arrest] if taken in large doses .<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " arrest\n",
      "\n",
      " Text excerpt - B:\n",
      "<start>shot perhaps 'artistically' with handheld cameras and apparently no movie lights by joaquin baca-asay , the low-budget production swings annoyingly between vert[igo] and opacity .<end> \n",
      "\n",
      "Highly activating tokens:\n",
      "igo\n",
      "\n",
      "Explanation of neuron 2 behavior: the main thing this neuron does is find\n",
      "\n",
      "assistant:  words related to physical medical conditions.\n",
      "\n",
      "user: \n",
      "\n",
      "Neuron 3\n",
      "Activations:\n",
      "\n",
      " Text excerpt - A:\n",
      "<start>the sense of together[ness] in our town is strong .<end> \n",
      "\n",
      "Highly activating tokens:\n",
      "ness\n",
      "\n",
      " Text excerpt - B:\n",
      "<start>a buoyant romantic comedy about friendship , love , and the truth that we['re] all[ in][ this][ together] .<end> \n",
      "\n",
      "Highly activating tokens:\n",
      "'re, in, this, together\n",
      "\n",
      "Explanation of neuron 3 behavior: the main thing this neuron does is find\n",
      "\n",
      "assistant:  phrases related to community.\n",
      "\n",
      "user: \n",
      "\n",
      "Neuron 4\n",
      "Activations:\n",
      "\n",
      " Text excerpt - A:\n",
      "<start> God give two men or[ two] women a \"right\" to marry one another and then adopt children with the approval of the state? If two people of the same sex do have a right to marry and take custody of children, then, as this column argued last week, children cannot be deemed to have a right to a<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " two\n",
      "\n",
      " Text excerpt - B:\n",
      "<start>http://archive.is/Hom3f\n",
      "\n",
      "also of interest, the street address for james achilles, secretary of kidzworld.com and kidzwerld.com (two spellings,[ two] different ip addresses) is shared by a shoddy looking massage parlour in vancouver -<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " two\n",
      "\n",
      " Text excerpt - C:\n",
      "<start>formerly, previously, in the past, at one time,[ at][ one] point, once upon a time, on a former occasion, on one[ occasion],[ one][ time], in[ one] case,[ time] was when, in days gone by,[ in] times[ gone] by, back in the day,[ in][ times] past,[ in] the old days<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " at, one, occasion, one, time, one, time, in, gone, in, times, in\n",
      "\n",
      " Text excerpt - D:\n",
      "<start> (vanilla) or brown (chocolate). Sheet cakes and square cakes are best; you'll need to cut off only the corner to announce your baby's sex. If you're expecting multiples, you could get a large sheet cake that is baked half and[ half], with clear delineation on the top for the<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " half\n",
      "\n",
      " Text excerpt - E:\n",
      "<start> moment I'm laughing because I don't want to cry â€“ I'm on the border. And that's hard you know. We came here twice,[ twice] we got beaten. Sydney have got seven points out of us\".\n",
      "\n",
      "\"But in the end there were four guys out there on $5000 wages. Can you<end> \n",
      "\n",
      "Highly activating tokens:\n",
      " twice\n",
      "\n",
      "Explanation of neuron 4 behavior: the main thing this neuron does is find\n",
      "\n",
      "explanation='the number-related tokens and variations.'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = open(os.path.join(os.path.expanduser(\"~\"), \".openai_api_key\"), \"r\").read()[:-1]\n",
    "\n",
    "from neuron_explainer.activations.activation_records import calculate_max_activation\n",
    "from neuron_explainer.activations.activations import ActivationRecordSliceParams, load_neuron\n",
    "from neuron_explainer.explanations.calibrated_simulator import UncalibratedNeuronSimulator\n",
    "from neuron_explainer.explanations.explainer import TokenActivationPairExplainer, SummaryExplainer, HighlightExplainer, HighlightSummaryExplainer\n",
    "from neuron_explainer.explanations.prompt_builder import PromptFormat\n",
    "from neuron_explainer.explanations.scoring import simulate_and_score\n",
    "from neuron_explainer.explanations.simulator import ExplanationNeuronSimulator\n",
    "\n",
    "EXPLAINER_MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "SIMULATOR_MODEL_NAME = \"gpt-3.5-turbo-instruct\"\n",
    "MODE = \"HighlightSummary\"#\"Original\"#\"Summary\"#\"Fixed\"#\"Highlight\"#\"HighlightSummary\"\n",
    "to_print = False #whether to print the prompt used\n",
    "neuron_record = load_neuron(9, 6236)\n",
    "\n",
    "cutoff = neuron_record.quantile_boundaries[2]\n",
    "print(\"Explainer: {} - Cutoff:{:.3f}\\n\".format(MODE, cutoff))\n",
    "# Grab the activation records we'll need.\n",
    "slice_params = ActivationRecordSliceParams(n_examples_per_split=5)\n",
    "train_activation_records = neuron_record.train_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "valid_activation_records = neuron_record.valid_activation_records(\n",
    "    activation_record_slice_params=slice_params\n",
    ")\n",
    "\n",
    "if MODE==\"Summary\":\n",
    "    explainer = SummaryExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        num_samples=1,\n",
    "        to_print = to_print\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "\n",
    "if MODE==\"Highlight\":\n",
    "    explainer = HighlightExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        num_samples=1,\n",
    "        to_print = to_print,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "    \n",
    "if MODE==\"HighlightSummary\":\n",
    "    explainer = HighlightSummaryExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        num_samples=1,\n",
    "        to_print = to_print,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "    \n",
    "    \n",
    "elif MODE==\"Original\":\n",
    "    explainer = TokenActivationPairExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        max_activation=calculate_max_activation(train_activation_records),\n",
    "        num_samples=1,\n",
    "        to_print = to_print,\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "\n",
    "elif MODE==\"AVHS\":\n",
    "    elif MODE==\"AVHS\":\n",
    "    explainer = AVHSExplainer(\n",
    "        model_name=EXPLAINER_MODEL_NAME,\n",
    "        prompt_format=PromptFormat.HARMONY_V4,\n",
    "        max_concurrent=1,\n",
    "    )\n",
    "\n",
    "    explanations = await explainer.generate_explanations(\n",
    "        all_activation_records=train_activation_records,\n",
    "        cutoff=cutoff,\n",
    "        max_activation=calculate_max_activation(train_activation_records),\n",
    "        num_samples=1,\n",
    "        to_print = to_print\n",
    "    )\n",
    "    assert len(explanations) == 1\n",
    "    explanation = explanations[0]\n",
    "\n",
    "elif MODE==\"Fixed\":\n",
    "    explanation = \"transition words at the beginning of sentences.\"\n",
    "    \n",
    "print(f\"{explanation=}\")\n",
    "\n",
    "# Simulate and score the explanation.\n",
    "# simulator = UncalibratedNeuronSimulator(\n",
    "#     ExplanationNeuronSimulator(\n",
    "#         SIMULATOR_MODEL_NAME,\n",
    "#         explanation,\n",
    "#         max_concurrent=1,\n",
    "#         prompt_format=PromptFormat.INSTRUCTION_FOLLOWING,\n",
    "#     )\n",
    "# )\n",
    "# scored_simulation = await simulate_and_score(simulator, valid_activation_records)\n",
    "# print(f\"score={scored_simulation.get_preferred_score():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
